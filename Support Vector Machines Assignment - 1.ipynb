{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e263b2e",
   "metadata": {},
   "source": [
    "Q1. What is the mathematical formula for a linear SVM?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e2d846",
   "metadata": {},
   "source": [
    "The mathematical formula for a linear Support Vector Machine (SVM) can be represented as:\n",
    "\n",
    "    f(x)=w.x+b\n",
    "\n",
    "\n",
    "where:\n",
    "- f(x) represents the decision function\n",
    "- w is the weight vector\n",
    "- x is the input vector\n",
    "- b is the bias term"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3dbc22",
   "metadata": {},
   "source": [
    "Q2. What is the objective function of a linear SVM?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b80192",
   "metadata": {},
   "source": [
    "The objective function of a linear Support Vector Machine (SVM) is to minimize the hinge loss function, which is expressed as:\n",
    "\n",
    "min w,b (||w||/2)+Ci ∑i=1 to n ζi\n",
    "w is the weight vector\n",
    "b is the bias term\n",
    "C is the regularization parameter\n",
    "yi is the true class label for the ith training example\n",
    "ζi is the ith training example vector\n",
    "n is the number of training examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ce5ae7",
   "metadata": {},
   "source": [
    "Q3. What is the kernel trick in SVM?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a2c275",
   "metadata": {},
   "source": [
    "The kernel trick in Support Vector Machines (SVM) is a technique that allows SVMs to handle non-linearly separable data by implicitly mapping the input vectors into a higher-dimensional feature space using a kernel function. This higher-dimensional space enables the SVM to find a linear decision boundary that effectively separates the data points. The kernel trick avoids the need to explicitly compute and store the transformed feature vectors, making it computationally efficient for handling complex datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cbbba0",
   "metadata": {},
   "source": [
    "Q4. What is the role of support vectors in SVM Explain with example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b049e963",
   "metadata": {},
   "source": [
    "Support vectors play a crucial role in Support Vector Machines (SVM) as they are the data points closest to the decision boundary (hyperplane) that determine the placement and orientation of the hyperplane. These points have the potential to influence the position and orientation of the decision boundary.\n",
    "\n",
    "Let's explain this with an example:\n",
    "\n",
    "Suppose you have a dataset with two classes, labeled as positive (+1) and negative (-1), and the data points are represented in a two-dimensional space. The goal is to find a linear decision boundary (hyperplane) that effectively separates these two classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0149ad84",
   "metadata": {},
   "source": [
    "Q5. Illustrate with examples and graphs of Hyperplane, Marginal plane, Soft margin and Hard margin in\n",
    "SVM?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e0ab31",
   "metadata": {},
   "source": [
    "Certainly! Here's a brief illustration of Hyperplane, Marginal plane, Soft margin, and Hard margin in Support Vector Machines (SVM) using examples and graphs:\n",
    "\n",
    "1. **Hyperplane**:\n",
    "   - Example: Consider a binary classification problem with two classes, labeled as positive (+1) and negative (-1). The hyperplane is the decision boundary that separates these classes.\n",
    "   - Graph: In a two-dimensional feature space, the hyperplane is a straight line. In higher dimensions, it's a hyperplane.\n",
    "\n",
    "2. **Marginal plane**:\n",
    "   - Example: The marginal plane is formed by the support vectors, which are the data points closest to the hyperplane.\n",
    "   - Graph: It's the region that includes the support vectors and has a margin (distance) from the hyperplane.\n",
    "\n",
    "3. **Soft Margin**:\n",
    "   - Example: Soft margin SVM allows for some misclassification to handle noisy or overlapping data.\n",
    "   - Graph: The soft margin allows for data points to fall within the margin or even on the wrong side of the hyperplane if necessary, represented by circles (misclassified points).\n",
    "\n",
    "4. **Hard Margin**:\n",
    "   - Example: Hard margin SVM enforces strict classification without allowing any misclassification.\n",
    "   - Graph: The hard margin does not tolerate any misclassification and requires all data points to be correctly classified, represented by crosses (correctly classified points).\n",
    "\n",
    "In these illustrations, the green line represents the hyperplane, the dashed lines represent the margins, and the circles (soft margin) or crosses (hard margin) represent the data points. The goal of SVM is to find the optimal hyperplane that maximizes the margin while minimizing classification errors, taking into account whether it's a soft margin or hard margin scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032fca85",
   "metadata": {},
   "source": [
    "Q6. SVM Implementation through Iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da770531",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4aed878b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caa4bd02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': 'iris.csv',\n",
       " 'data_module': 'sklearn.datasets.data'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4857bfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d52330b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pd.DataFrame(data.data,columns=data.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bc25216",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e5437f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0968bd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dbd37f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "baa110ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((112, 4), (38, 4))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ad7872f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5305f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc=SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89768ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7db873d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.04631136,  0.52105578, -1.0030165 , -0.46411816],\n",
       "       [-0.00641373,  0.17867392, -0.5389119 , -0.29158729],\n",
       "       [ 0.57613513,  1.19215085, -2.03465638, -1.67923323]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "988e84d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b7742e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "05e2a82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       1.00      1.00      1.00        11\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        38\n",
      "   macro avg       1.00      1.00      1.00        38\n",
      "weighted avg       1.00      1.00      1.00        38\n",
      "\n",
      "[[15  0  0]\n",
      " [ 0 11  0]\n",
      " [ 0  0 12]]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb42d763",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid={\n",
    "    'C':[0.1,1,10,100,1000],\n",
    "    'gamma':[1,0.1,0.01,0.001,0.0001]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5738b815",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4eeffb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "svclf=GridSearchCV(svc,param_grid=param_grid,refit=True,cv=5,verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ecfcb59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV 1/5] END ....................C=0.1, gamma=1;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END ....................C=0.1, gamma=1;, score=0.957 total time=   0.0s\n",
      "[CV 3/5] END ....................C=0.1, gamma=1;, score=0.818 total time=   0.0s\n",
      "[CV 4/5] END ....................C=0.1, gamma=1;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ....................C=0.1, gamma=1;, score=0.955 total time=   0.0s\n",
      "[CV 1/5] END ..................C=0.1, gamma=0.1;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END ..................C=0.1, gamma=0.1;, score=0.957 total time=   0.0s\n",
      "[CV 3/5] END ..................C=0.1, gamma=0.1;, score=0.818 total time=   0.0s\n",
      "[CV 4/5] END ..................C=0.1, gamma=0.1;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ..................C=0.1, gamma=0.1;, score=0.955 total time=   0.0s\n",
      "[CV 1/5] END .................C=0.1, gamma=0.01;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END .................C=0.1, gamma=0.01;, score=0.957 total time=   0.0s\n",
      "[CV 3/5] END .................C=0.1, gamma=0.01;, score=0.818 total time=   0.0s\n",
      "[CV 4/5] END .................C=0.1, gamma=0.01;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .................C=0.1, gamma=0.01;, score=0.955 total time=   0.0s\n",
      "[CV 1/5] END ................C=0.1, gamma=0.001;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END ................C=0.1, gamma=0.001;, score=0.957 total time=   0.0s\n",
      "[CV 3/5] END ................C=0.1, gamma=0.001;, score=0.818 total time=   0.0s\n",
      "[CV 4/5] END ................C=0.1, gamma=0.001;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ................C=0.1, gamma=0.001;, score=0.955 total time=   0.0s\n",
      "[CV 1/5] END ...............C=0.1, gamma=0.0001;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END ...............C=0.1, gamma=0.0001;, score=0.957 total time=   0.0s\n",
      "[CV 3/5] END ...............C=0.1, gamma=0.0001;, score=0.818 total time=   0.0s\n",
      "[CV 4/5] END ...............C=0.1, gamma=0.0001;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ...............C=0.1, gamma=0.0001;, score=0.955 total time=   0.0s\n",
      "[CV 1/5] END ......................C=1, gamma=1;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END ......................C=1, gamma=1;, score=0.957 total time=   0.0s\n",
      "[CV 3/5] END ......................C=1, gamma=1;, score=0.864 total time=   0.0s\n",
      "[CV 4/5] END ......................C=1, gamma=1;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ......................C=1, gamma=1;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ....................C=1, gamma=0.1;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END ....................C=1, gamma=0.1;, score=0.957 total time=   0.0s\n",
      "[CV 3/5] END ....................C=1, gamma=0.1;, score=0.864 total time=   0.0s\n",
      "[CV 4/5] END ....................C=1, gamma=0.1;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ....................C=1, gamma=0.1;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ...................C=1, gamma=0.01;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END ...................C=1, gamma=0.01;, score=0.957 total time=   0.0s\n",
      "[CV 3/5] END ...................C=1, gamma=0.01;, score=0.864 total time=   0.0s\n",
      "[CV 4/5] END ...................C=1, gamma=0.01;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ...................C=1, gamma=0.01;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ..................C=1, gamma=0.001;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END ..................C=1, gamma=0.001;, score=0.957 total time=   0.0s\n",
      "[CV 3/5] END ..................C=1, gamma=0.001;, score=0.864 total time=   0.0s\n",
      "[CV 4/5] END ..................C=1, gamma=0.001;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ..................C=1, gamma=0.001;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END .................C=1, gamma=0.0001;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END .................C=1, gamma=0.0001;, score=0.957 total time=   0.0s\n",
      "[CV 3/5] END .................C=1, gamma=0.0001;, score=0.864 total time=   0.0s\n",
      "[CV 4/5] END .................C=1, gamma=0.0001;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .................C=1, gamma=0.0001;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END .....................C=10, gamma=1;, score=0.957 total time=   0.0s\n",
      "[CV 2/5] END .....................C=10, gamma=1;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END .....................C=10, gamma=1;, score=0.818 total time=   0.0s\n",
      "[CV 4/5] END .....................C=10, gamma=1;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .....................C=10, gamma=1;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ...................C=10, gamma=0.1;, score=0.957 total time=   0.0s\n",
      "[CV 2/5] END ...................C=10, gamma=0.1;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ...................C=10, gamma=0.1;, score=0.818 total time=   0.0s\n",
      "[CV 4/5] END ...................C=10, gamma=0.1;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ...................C=10, gamma=0.1;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ..................C=10, gamma=0.01;, score=0.957 total time=   0.0s\n",
      "[CV 2/5] END ..................C=10, gamma=0.01;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ..................C=10, gamma=0.01;, score=0.818 total time=   0.0s\n",
      "[CV 4/5] END ..................C=10, gamma=0.01;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ..................C=10, gamma=0.01;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END .................C=10, gamma=0.001;, score=0.957 total time=   0.0s\n",
      "[CV 2/5] END .................C=10, gamma=0.001;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END .................C=10, gamma=0.001;, score=0.818 total time=   0.0s\n",
      "[CV 4/5] END .................C=10, gamma=0.001;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .................C=10, gamma=0.001;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ................C=10, gamma=0.0001;, score=0.957 total time=   0.0s\n",
      "[CV 2/5] END ................C=10, gamma=0.0001;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ................C=10, gamma=0.0001;, score=0.818 total time=   0.0s\n",
      "[CV 4/5] END ................C=10, gamma=0.0001;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ................C=10, gamma=0.0001;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ....................C=100, gamma=1;, score=0.957 total time=   0.0s\n",
      "[CV 2/5] END ....................C=100, gamma=1;, score=0.957 total time=   0.0s\n",
      "[CV 3/5] END ....................C=100, gamma=1;, score=0.818 total time=   0.0s\n",
      "[CV 4/5] END ....................C=100, gamma=1;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ....................C=100, gamma=1;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ..................C=100, gamma=0.1;, score=0.957 total time=   0.0s\n",
      "[CV 2/5] END ..................C=100, gamma=0.1;, score=0.957 total time=   0.0s\n",
      "[CV 3/5] END ..................C=100, gamma=0.1;, score=0.818 total time=   0.0s\n",
      "[CV 4/5] END ..................C=100, gamma=0.1;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ..................C=100, gamma=0.1;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END .................C=100, gamma=0.01;, score=0.957 total time=   0.0s\n",
      "[CV 2/5] END .................C=100, gamma=0.01;, score=0.957 total time=   0.0s\n",
      "[CV 3/5] END .................C=100, gamma=0.01;, score=0.818 total time=   0.0s\n",
      "[CV 4/5] END .................C=100, gamma=0.01;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .................C=100, gamma=0.01;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ................C=100, gamma=0.001;, score=0.957 total time=   0.0s\n",
      "[CV 2/5] END ................C=100, gamma=0.001;, score=0.957 total time=   0.0s\n",
      "[CV 3/5] END ................C=100, gamma=0.001;, score=0.818 total time=   0.0s\n",
      "[CV 4/5] END ................C=100, gamma=0.001;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ................C=100, gamma=0.001;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ...............C=100, gamma=0.0001;, score=0.957 total time=   0.0s\n",
      "[CV 2/5] END ...............C=100, gamma=0.0001;, score=0.957 total time=   0.0s\n",
      "[CV 3/5] END ...............C=100, gamma=0.0001;, score=0.818 total time=   0.0s\n",
      "[CV 4/5] END ...............C=100, gamma=0.0001;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ...............C=100, gamma=0.0001;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ...................C=1000, gamma=1;, score=0.957 total time=   0.0s\n",
      "[CV 2/5] END ...................C=1000, gamma=1;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ...................C=1000, gamma=1;, score=0.818 total time=   0.0s\n",
      "[CV 4/5] END ...................C=1000, gamma=1;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ...................C=1000, gamma=1;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END .................C=1000, gamma=0.1;, score=0.957 total time=   0.0s\n",
      "[CV 2/5] END .................C=1000, gamma=0.1;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END .................C=1000, gamma=0.1;, score=0.818 total time=   0.0s\n",
      "[CV 4/5] END .................C=1000, gamma=0.1;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .................C=1000, gamma=0.1;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ................C=1000, gamma=0.01;, score=0.957 total time=   0.0s\n",
      "[CV 2/5] END ................C=1000, gamma=0.01;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ................C=1000, gamma=0.01;, score=0.818 total time=   0.0s\n",
      "[CV 4/5] END ................C=1000, gamma=0.01;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ................C=1000, gamma=0.01;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ...............C=1000, gamma=0.001;, score=0.957 total time=   0.0s\n",
      "[CV 2/5] END ...............C=1000, gamma=0.001;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ...............C=1000, gamma=0.001;, score=0.818 total time=   0.0s\n",
      "[CV 4/5] END ...............C=1000, gamma=0.001;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ...............C=1000, gamma=0.001;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ..............C=1000, gamma=0.0001;, score=0.957 total time=   0.0s\n",
      "[CV 2/5] END ..............C=1000, gamma=0.0001;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ..............C=1000, gamma=0.0001;, score=0.818 total time=   0.0s\n",
      "[CV 4/5] END ..............C=1000, gamma=0.0001;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ..............C=1000, gamma=0.0001;, score=1.000 total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=SVC(kernel=&#x27;linear&#x27;),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100, 1000],\n",
       "                         &#x27;gamma&#x27;: [1, 0.1, 0.01, 0.001, 0.0001]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=SVC(kernel=&#x27;linear&#x27;),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100, 1000],\n",
       "                         &#x27;gamma&#x27;: [1, 0.1, 0.01, 0.001, 0.0001]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(kernel='linear'),\n",
       "             param_grid={'C': [0.1, 1, 10, 100, 1000],\n",
       "                         'gamma': [1, 0.1, 0.01, 0.001, 0.0001]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svclf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d5a6be16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'gamma': 1}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svclf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f6d1df91",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=svclf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b86d988c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       1.00      1.00      1.00        11\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        38\n",
      "   macro avg       1.00      1.00      1.00        38\n",
      "weighted avg       1.00      1.00      1.00        38\n",
      "\n",
      "[[15  0  0]\n",
      " [ 0 11  0]\n",
      " [ 0  0 12]]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3d360bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [1. 1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class LinearSVM:\n",
    "    def __init__(self, learning_rate=0.01, epochs=1000, C=1):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.C = C\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "        \n",
    "        # Gradient descent training\n",
    "        for _ in range(self.epochs):\n",
    "            for idx, x_i in enumerate(X):\n",
    "                condition = y[idx] * (np.dot(x_i, self.weights) - self.bias) >= 1\n",
    "                if condition:\n",
    "                    self.weights -= self.learning_rate * (2 * self.C * self.weights)\n",
    "                else:\n",
    "                    self.weights -= self.learning_rate * (2 * self.C * self.weights - np.dot(x_i, y[idx]))\n",
    "                    self.bias -= self.learning_rate * y[idx]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.sign(np.dot(X, self.weights) - self.bias)\n",
    "\n",
    "# Example usage\n",
    "X_train = np.array([[1, 2], [2, 3], [3, 3], [2, 1], [3, 2]])\n",
    "y_train = np.array([-1, -1, 1, 1, 1])\n",
    "\n",
    "# Create and train the linear SVM classifier from scratch\n",
    "svm_scratch = LinearSVM()\n",
    "svm_scratch.fit(X_train, y_train)\n",
    "\n",
    "# Example predictions\n",
    "X_test = np.array([[4, 5], [1, 1]])\n",
    "y_pred = svm_scratch.predict(X_test)\n",
    "print(\"Predictions:\", y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60eca5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
