{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1960784b",
   "metadata": {},
   "source": [
    "# Feature Engineering-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711b6684",
   "metadata": {},
   "source": [
    "Q1. What is Min-Max scaling, and how is it used in data preprocessing? Provide an example to illustrate its\n",
    "application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd32a956",
   "metadata": {},
   "source": [
    "Min-Max scaling is a data preprocessing technique used to scale and normalize the values of a feature within a specific range, typically between 0 and 1. The purpose of Min-Max scaling is to ensure that all the features contribute equally to the analysis and prevent certain features from dominating due to their larger magnitude.\n",
    "\n",
    "The formula for Min-Max scaling is as follows:\n",
    "Xscaler=(X−Xmin)/(Xmax−Xmin)\n",
    "\n",
    "\n",
    "Here's an example to illustrate Min-Max scaling:\n",
    "Suppose you have a dataset with a feature, let's call it \"Income,\" ranging from $20,000 to $100,000. The goal is to scale this feature to a range between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee086813",
   "metadata": {},
   "source": [
    "Q2. What is the Unit Vector technique in feature scaling, and how does it differ from Min-Max scaling?\n",
    "Provide an example to illustrate its application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e5a32b",
   "metadata": {},
   "source": [
    "The Unit Vector technique, also known as vector normalization or normalization to unit length, is a feature scaling method that scales each data point to have a length of 1 while preserving the direction of the data. In the context of feature scaling, this is often applied to scale the feature vectors (rows of the dataset) rather than individual features.\n",
    "\n",
    "The formula for Unit Vector scaling is as follows:\n",
    "Xscaled=X/|x|\n",
    "\n",
    "The Unit Vector technique is different from Min-Max scaling in that it focuses on scaling the entire vector, not just individual feature values. While Min-Max scaling transforms each feature to a common range, Unit Vector scaling ensures that each data point has a vector length of 1. This can be particularly useful in situations where the magnitude of the vector matters more than the actual values of individual features.\n",
    "\n",
    "Here's an example to illustrate Unit Vector scaling:\n",
    "\n",
    "Suppose you have a dataset with two features, \"Age\" and \"Income,\" and you want to scale each data point (row) to have a length of 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ad4934",
   "metadata": {},
   "source": [
    "Q3. What is PCA (Principle Component Analysis), and how is it used in dimensionality reduction? Provide an\n",
    "example to illustrate its application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326fd75a",
   "metadata": {},
   "source": [
    "Principal Component Analysis (PCA) is a dimensionality reduction technique used to transform high-dimensional data into a lower-dimensional representation while retaining as much of the original variance as possible. PCA achieves this by identifying the principal components, which are linear combinations of the original features, ordered by the amount of variance they explain.\n",
    "\n",
    "\n",
    "\n",
    "PCA is used to project the original data with two features (Height and Weight) into a lower-dimensional space with one principal component. The result is a one-dimensional representation that retains the most significant information from the original data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70efc524",
   "metadata": {},
   "source": [
    "Q4. What is the relationship between PCA and Feature Extraction, and how can PCA be used for Feature\n",
    "Extraction? Provide an example to illustrate this concept."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a71a43",
   "metadata": {},
   "source": [
    "PCA (Principal Component Analysis) can be used for feature extraction, and the relationship lies in the fact that PCA extracts a set of new features, called principal components, from the original features of a dataset. These principal components are linear combinations of the original features and are ordered by the amount of variance they capture. By selecting a subset of these principal components, one can effectively perform feature extraction, reducing the dimensionality of the data while retaining the most important information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d8956a",
   "metadata": {},
   "source": [
    "Q5. You are working on a project to build a recommendation system for a food delivery service. The dataset\n",
    "contains features such as price, rating, and delivery time. Explain how you would use Min-Max scaling to\n",
    "preprocess the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60f661ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>DeliveryTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Price    Rating  DeliveryTime\n",
       "0  0.000000  0.833333         0.250\n",
       "1  0.666667  0.000000         0.625\n",
       "2  0.333333  1.000000         0.000\n",
       "3  1.000000  0.277778         1.000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "data = {\n",
    "    'Price': [10, 20, 15, 25],\n",
    "    'Rating': [4.5, 3.0, 4.8, 3.5],\n",
    "    'DeliveryTime': [30, 45, 20, 60]\n",
    "}\n",
    "df=pd.DataFrame(data)\n",
    "min_max=MinMaxScaler()\n",
    "min_max.fit(df[['Price','Rating','DeliveryTime']])\n",
    "pd.DataFrame(min_max.transform(df[['Price','Rating','DeliveryTime']]),columns=['Price','Rating','DeliveryTime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc692576",
   "metadata": {},
   "source": [
    "Q6. You are working on a project to build a model to predict stock prices. The dataset contains many\n",
    "features, such as company financial data and market trends. Explain how you would use PCA to reduce the\n",
    "dimensionality of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99da093",
   "metadata": {},
   "source": [
    "Principal Component Analysis (PCA) is a technique used for dimensionality reduction in datasets with many features. In the context of building a model to predict stock prices, if the dataset contains numerous features (such as various financial indicators and market trends), PCA can help simplify the dataset while retaining most of its important information. Here's a step-by-step explanation of how you might use PCA for dimensionality reduction in this scenario:\n",
    "\n",
    "Understand the Features:\n",
    "\n",
    "Begin by understanding the features in your dataset. In the context of stock prices, these features might include financial ratios, historical stock prices, market indicators, etc.\n",
    "Standardize the Data:\n",
    "\n",
    "Standardize or normalize the data to ensure that all features are on a similar scale. This is important for PCA, as it is sensitive to the scale of the variables.\n",
    "Calculate the Covariance Matrix:\n",
    "\n",
    "Compute the covariance matrix of the standardized data. The covariance matrix provides information about the relationships between different features.\n",
    "Calculate Eigenvectors and Eigenvalues:\n",
    "\n",
    "Find the eigenvectors and eigenvalues of the covariance matrix. These eigenvectors represent the principal components, and the corresponding eigenvalues indicate the amount of variance captured by each principal component.\n",
    "Sort Eigenvalues:\n",
    "\n",
    "Sort the eigenvalues in descending order. The higher the eigenvalue, the more variance is explained by the corresponding eigenvector (principal component).\n",
    "Select Principal Components:\n",
    "\n",
    "Choose the top k eigenvectors that correspond to the k highest eigenvalues. The idea is to retain a sufficient amount of variance in the data. You might choose a number of principal components that explain a certain percentage of the total variance, such as 95% or 99%.\n",
    "Projection:\n",
    "\n",
    "Project the original data onto the selected principal components. This involves multiplying the standardized data by the matrix of selected principal components.\n",
    "Reduced Dimensionality:\n",
    "\n",
    "The resulting dataset will have reduced dimensionality, with the number of features reduced to the chosen number of principal components (k).\n",
    "Model Training:\n",
    "\n",
    "Train your predictive model using the dataset with reduced dimensionality. This can lead to faster training times and potentially improved generalization to new, unseen data.\n",
    "Evaluate and Fine-Tune:\n",
    "\n",
    "Evaluate the performance of your model on a validation set. If necessary, fine-tune the number of principal components based on the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1c4f48",
   "metadata": {},
   "source": [
    "Q7. For a dataset containing the following values: [1, 5, 10, 15, 20], perform Min-Max scaling to transform the\n",
    "values to a range of -1 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94366691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   value\n",
       "0      1\n",
       "1      5\n",
       "2     10\n",
       "3     15\n",
       "4     20"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'value': [1, 5, 10, 15, 20]})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "344d78b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.210526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.473684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.736842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      value\n",
       "0  0.000000\n",
       "1  0.210526\n",
       "2  0.473684\n",
       "3  0.736842\n",
       "4  1.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "min_max=MinMaxScaler()\n",
    "pd.DataFrame(min_max.fit_transform(df[['value']]),columns=min_max.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e67fef1",
   "metadata": {},
   "source": [
    "Q8. For a dataset containing the following features: [height, weight, age, gender, blood pressure], perform\n",
    "Feature Extraction using PCA. How many principal components would you choose to retain, and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bb2e7b",
   "metadata": {},
   "source": [
    "The decision on how many principal components to retain in a feature extraction process using PCA depends on the desired amount of variance to be preserved and the trade-off between dimensionality reduction and information loss. Here are the general steps to determine the number of principal components to retain:\n",
    "Compute the Covariance Matrix,Calculate Eigenvalues and Eigenvectors,Sort Eigenvalues,Calculate Cumulative Variance,Choose the Number of Principal Components,Perform Dimensionality Reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47932c85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
